import streamlit as st
import os
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import google.generativeai as genai
from duckduckgo_search import DDGS
from urllib.parse import urlparse

# ==========================================
# ğŸ”‘ [í•„ìˆ˜] Gemini API í‚¤ ì„¤ì •
# ==========================================
try:
    GOOG_API_KEY = st.secrets["GOOG_API_KEY"]
except:
    GOOG_API_KEY = "ì—¬ê¸°ì—_ë°œê¸‰ë°›ì€_API_í‚¤ë¥¼_ë¶™ì—¬ë„£ìœ¼ì„¸ìš”" # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì£¼ì‹ í…Œë§ˆ ë¶„ì„ê¸° (AI Ver.)", layout="wide")
st.title("ğŸ¤– AI ì£¼ì‹ íˆ¬ì ì „ëµê°€ (Hojae Focus + Data View)")

# --- [ëª¨ë¸ ëª©ë¡] ---
@st.cache_data
def get_available_gemini_models(api_key):
    try:
        genai.configure(api_key=api_key)
        models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace("models/", "")
                display_name = name
                if "1.5-flash" in name and "latest" not in name and "8b" not in name:
                     display_name = f"âœ… {name} (ì¶”ì²œ:ë¬´í•œì²´ë ¥)"
                elif "2.0" in name or "exp" in name:
                     display_name = f"ğŸ§ª {name} (ìµœì‹ /ì²´ë ¥ì•½í•¨)"
                models.append(display_name)
        models.sort(key=lambda x: "âœ…" not in x)
        return models
    except:
        return ["âœ… gemini-1.5-flash (ê¸°ë³¸)", "gemini-pro"]

# --- [ë‰´ìŠ¤ ë³¸ë¬¸ ì½ê¸°] ---
def fetch_url_content(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=3)
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        paragraphs = soup.find_all('p')
        content = " ".join([p.text.strip() for p in paragraphs])
        if len(content) < 50: return None
        # [ë°ì´í„°ëŸ‰ ì¡°ì ˆ] ë„ˆë¬´ ê¸¸ë©´ 2000ìì—ì„œ ìë¦„
        return content[:2000] + "..." if len(content) > 2000 else content
    except: return None

# --- [ë‰´ìŠ¤ ê²€ìƒ‰] ë°ì´í„°ëŸ‰ í™•ì¸ ê¸°ëŠ¥ ì¶”ê°€ ---
def search_news_strict(keyword):
    search_context = ""
    total_chars = 0 # ê¸€ììˆ˜ ì„¸ê¸°
    
    try:
        results = list(DDGS().news(keywords=keyword, region='kr-kr', safesearch='off', max_results=7))
        if results:
            for i, res in enumerate(results):
                title = res.get('title', '-')
                link = res.get('url', res.get('href', ''))
                source = res.get('source', 'News') 
                date = res.get('date', '')
                
                full_body = None
                tag = "ğŸ“„ [ìš”ì•½]"
                content_to_use = res.get('body', res.get('snippet', ''))

                # ìƒìœ„ 3ê°œ ë³¸ë¬¸ ì½ê¸°
                if i < 3 and link: 
                    full_body = fetch_url_content(link)
                
                if full_body:
                    content_to_use = f"Analyzed Full Text: {full_body}"
                    tag = "ğŸ“– [ë³¸ë¬¸ ì™„ë…]"
                
                entry = f"[{i+1}] [{source}] {title} ({date}) {tag}\në‚´ìš©: {content_to_use}\n\n"
                search_context += entry
                total_chars += len(entry) # ê¸€ììˆ˜ ëˆ„ì 
        else:
            search_context = "ê´€ë ¨ëœ ë‰´ìŠ¤ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        return search_context, total_chars # í…ìŠ¤íŠ¸ì™€ ê¸€ììˆ˜ ë°˜í™˜
    except Exception as e:
        return f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}", 0

# --- [ì‚¬ì´ë“œë°”] ---
with st.sidebar:
    st.header("ğŸ” ì»¨íŠ¸ë¡¤ íŒ¨ë„")
    if st.button("ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ğŸ”„"):
        st.cache_data.clear()
        if "messages" in st.session_state:
            st.session_state.messages = []
    st.markdown("---")
    
    if GOOG_API_KEY.startswith("AIza"):
        model_options = get_available_gemini_models(GOOG_API_KEY)
        selected_display = st.selectbox("ì‚¬ìš©í•  ëª¨ë¸:", model_options, index=0)
        selected_real_name = selected_display.split(" ")[1] if " " in selected_display else selected_display
    else:
        st.error("API í‚¤ í•„ìš”")
        selected_real_name = "gemini-1.5-flash"
    
    use_grounding = st.checkbox("ğŸŒ ì‹¬ì¸µ ë‰´ìŠ¤ ê²€ìƒ‰(Deep Search)", value=True)
    st.info(f"ì„ íƒë¨: `{selected_real_name}`")

# --- ìœ í‹¸ë¦¬í‹° ---
def extract_code(link):
    match = re.search(r'code=([a-zA-Z0-9]+)', link)
    if match: return match.group(1)
    return None

def clean_text(text):
    if not text: return "-"
    return re.sub(r'[^ê°€-í£0-9a-zA-Z.]', '', text)

# --- [AI ì‘ë‹µ í•¨ìˆ˜] í”„ë¡¬í”„íŠ¸ ê°•ë ¥ ìˆ˜ì • ---
def get_gemini_response_hojae(messages, model_name, use_search, stock_name, theme):
    genai.configure(api_key=GOOG_API_KEY)
    
    # 1. ê²€ìƒ‰ ì‹¤í–‰ (ë°ì´í„°ëŸ‰ ì‹œê°í™” í¬í•¨)
    current_query = messages[-1]['content']
    is_system_prompt = "ë‹¹ì‹ ì€" in current_query
    
    search_result_text = ""
    data_log = ""
    
    if use_search:
        if is_system_prompt:
            search_query = f"{stock_name} {theme} ì£¼ê°€ ì „ë§ í˜¸ì¬ íŠ¹ì§•ì£¼"
        else:
            search_query = f"{stock_name} {current_query}"
        
        with st.spinner(f"ğŸ“° '{search_query}' ê´€ë ¨ í˜¸ì¬ë¥¼ ì±„êµ´ ì¤‘..."):
            search_data, char_count = search_news_strict(search_query)
            
            # [ì‹œê°í™”] ë°ì´í„°ëŸ‰ ë³´ì—¬ì£¼ê¸°
            with st.expander(f"ğŸ“Š AIê°€ ì½ì€ ë°ì´í„°ëŸ‰: ì´ {char_count:,}ì (í´ë¦­í•´ì„œ ì›ë¬¸ ë³´ê¸°)"):
                st.info(f"ë‰´ìŠ¤ 7ê±´ (ìƒìœ„ 3ê±´ ë³¸ë¬¸ í¬í•¨)ì„ ë¶„ì„í•©ë‹ˆë‹¤. ì´ëŠ” ì›ê³ ì§€ ì•½ {char_count // 200}ì¥ ë¶„ëŸ‰ì…ë‹ˆë‹¤.")
                st.text(search_data)
                
        search_result_text = f"\n\n[ğŸ“° ê²€ìƒ‰ëœ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„°]:\n{search_data}\n"

    # 2. ë©”ì‹œì§€ êµ¬ì„±
    modified_messages = []
    for i, msg in enumerate(messages):
        content = msg['content']
        if i == len(messages) - 1 and use_search:
            content += search_result_text
        role = "user" if msg["role"] == "user" else "model"
        modified_messages.append({"role": role, "parts": [content]})

    # 3. ëª¨ë¸ í˜¸ì¶œ (ìë™ ë³µêµ¬)
    target_models = [model_name, "gemini-1.5-flash"]
    if "1.5-flash" in model_name: target_models = ["gemini-1.5-flash"]

    for m_name in target_models:
        try:
            full_name = f"models/{m_name}" if "models/" not in m_name else m_name
            model = genai.GenerativeModel(full_name)
            response = model.generate_content(modified_messages, stream=True)
            for chunk in response:
                yield chunk.text
            break
        except Exception as e:
            if "Quota" in str(e) or "429" in str(e):
                if m_name != target_models[-1]:
                    yield f"\n\nâš ï¸ **[{m_name}] ìš©ëŸ‰ ì´ˆê³¼! íŠ¼íŠ¼í•œ 1.5-flashë¡œ ì „í™˜í•©ë‹ˆë‹¤...**\n\n"
                    time.sleep(1)
                    continue
                else: yield "ğŸš¨ ëª¨ë“  ëª¨ë¸ í• ë‹¹ëŸ‰ ì´ˆê³¼."
            else: yield f"ì˜¤ë¥˜: {e}"

# --- ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜ë“¤ (ìƒëµ ì—†ì´ í¬í•¨) ---
@st.cache_data
def get_naver_themes():
    url = "https://finance.naver.com/sise/theme.naver"
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers)
        response.encoding = 'cp949' 
        soup = BeautifulSoup(response.text, 'html.parser')
        rows = soup.select("#contentarea_left > table.type_1 > tr")
        data = []
        for row in rows:
            cols = row.select("td")
            if len(cols) >= 4:
                theme_name = cols[0].text.strip()
                link = "https://finance.naver.com" + cols[0].find('a')['href']
                data.append({"í…Œë§ˆëª…": theme_name, "ë§í¬": link})
        return pd.DataFrame(data).head(20)
    except: return pd.DataFrame()

def get_theme_details(theme_link):
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(theme_link, headers=headers)
        response.encoding = 'cp949'
        soup = BeautifulSoup(response.text, 'html.parser')
        rows = soup.select("table.type_5 > tbody > tr")
        stock_info = []
        for row in rows:
            cols = row.select("td")
            if len(cols) > 4: 
                name_tag = cols[0].find('a')
                if not name_tag: continue
                name = name_tag.text.strip()
                link = "https://finance.naver.com" + name_tag['href']
                code = extract_code(link)
                price = cols[2].text.strip()
                diff_rate_str = cols[4].text.strip().replace('\n', '').strip()
                try: diff_rate_val = float(diff_rate_str.replace('%', '').replace('+', ''))
                except: diff_rate_val = -999.0
                formatted_price = f"{price} ({diff_rate_str})"
                stock_info.append({'name': name, 'code': code, 'price_str': formatted_price, 'diff_rate_val': diff_rate_val, 'link': link})
        return stock_info
    except: return []

@st.cache_data
def get_all_theme_stocks():
    df_themes = get_naver_themes()
    all_stocks = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(df_themes)
    for index, row in df_themes.iterrows():
        theme_name = row['í…Œë§ˆëª…']
        theme_link = row['ë§í¬']
        status_text.text(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({index+1}/{total}): {theme_name}")
        progress_bar.progress((index + 1) / total)
        stocks_info = get_theme_details(theme_link)
        stocks_info.sort(key=lambda x: x['diff_rate_val'], reverse=True)
        for rank, stock in enumerate(stocks_info, 1):
            rank_display = f"ğŸ‘‘ 1ìœ„" if rank == 1 else f"{rank}ìœ„"
            all_stocks.append({"ì¢…ëª©ëª…": stock['name'], "ì¢…ëª©ì½”ë“œ": stock['code'], "í…Œë§ˆëª…": theme_name, "í˜„ì¬ê°€(ë“±ë½ë¥ )": stock['price_str'], "í…Œë§ˆìˆœìœ„": rank_display, "ë§í¬": stock['link']})
        time.sleep(0.05)
    status_text.text("í…Œë§ˆ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    progress_bar.empty()
    return pd.DataFrame(all_stocks)

def get_latest_news(code):
    url = f"https://finance.naver.com/item/news_news.naver?code={code}"
    headers = {'User-Agent': 'Mozilla/5.0', 'Referer': f'https://finance.naver.com/item/main.naver?code={code}'}
    try:
        response = requests.get(url, headers=headers)
        response.encoding = 'cp949'
        soup = BeautifulSoup(response.text, 'html.parser')
        news_list = []
        articles = soup.select(".title > a")
        if not articles: articles = soup.select("a.tit")
        for article in articles[:20]: 
            title = article.text.strip()
            link = article['href']
            if link.startswith('/'): link = "https://finance.naver.com" + link
            news_list.append({"ì œëª©": title, "ë§í¬": link})
        return news_list
    except: return []

@st.cache_data
def get_top_risers_info():
    market_map = {} 
    for sosok, market_name in [(0, "KOSPI"), (1, "KOSDAQ")]: 
        url = f"https://finance.naver.com/sise/sise_rise.naver?sosok={sosok}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            response = requests.get(url, headers=headers)
            response.encoding = 'cp949'
            soup = BeautifulSoup(response.text, 'html.parser')
            items = soup.select("table.type_2 tr td a.tltle")
            for item in items[:150]: market_map[item.text.strip()] = market_name
        except: pass
    return market_map

@st.cache_data
def get_volume_leaders():
    tickers = []
    for sosok in [0, 1]:
        url = f"https://finance.naver.com/sise/sise_quant_high.naver?sosok={sosok}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.text, 'html.parser')
            items = soup.select("table.type_2 tr td a.tltle")
            for item in items[:100]: tickers.append(item.text.strip())
        except: pass
    return tickers

def get_stock_fundamentals(code):
    url = f"https://finance.naver.com/item/main.naver?code={code}"
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers)
        response.encoding = 'cp949'
        soup = BeautifulSoup(response.text, 'html.parser')
        market_cap_elem = soup.select_one("#_market_sum")
        if market_cap_elem: market_cap = clean_text(market_cap_elem.text.strip()) + "ì–µ"
        else: market_cap = "-"
        return {"ì‹œê°€ì´ì•¡": market_cap}
    except: return {"ì‹œê°€ì´ì•¡": "-"}

# --- ë©”ì¸ í™”ë©´ ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_code" not in st.session_state:
    st.session_state.last_code = None

try:
    with st.spinner('ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
        market_info_map = get_top_risers_info()
        list_A_names = list(market_info_map.keys())
        list_B = get_volume_leaders()
        df_C = get_all_theme_stocks()
        
    st.subheader("1ï¸âƒ£ êµì§‘í•© ë¶„ì„ ê²°ê³¼ (í•µì‹¬ ì£¼ë„ì£¼)")
    
    final_candidates = []
    for index, row in df_C.iterrows():
        stock_name = row['ì¢…ëª©ëª…']
        if (stock_name in list_A_names) and (stock_name in list_B):
            market_type = market_info_map.get(stock_name, "Unknown")
            row_data = row.to_dict()
            row_data['ì‹œì¥êµ¬ë¶„'] = market_type
            final_candidates.append(row_data)
    
    if final_candidates:
        df_final = pd.DataFrame(final_candidates)
        df_final = df_final.drop_duplicates(['ì¢…ëª©ëª…'])
        
        display_columns = ['í…Œë§ˆìˆœìœ„', 'ì‹œì¥êµ¬ë¶„', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€(ë“±ë½ë¥ )', 'í…Œë§ˆëª…']
        column_config = {
            "í…Œë§ˆìˆœìœ„": st.column_config.TextColumn("í…Œë§ˆ ìˆœìœ„", width="small"),
            "ì‹œì¥êµ¬ë¶„": st.column_config.TextColumn("ì‹œì¥", width="small"),
            "ì¢…ëª©ëª…": st.column_config.TextColumn("ì¢…ëª©ëª…", width="medium"),
            "í˜„ì¬ê°€(ë“±ë½ë¥ )": st.column_config.TextColumn("í˜„ì¬ê°€ (ë“±ë½ë¥ )", width="medium"),
            "í…Œë§ˆëª…": st.column_config.TextColumn("ê´€ë ¨ í…Œë§ˆ", width="large"),
        }
        
        event = st.dataframe(df_final[display_columns], use_container_width=True, hide_index=True, column_config=column_config, on_select="rerun", selection_mode="single-row")
        st.divider()
        
        if len(event.selection.rows) > 0:
            selected_index = event.selection.rows[0]
            selected_stock_data = df_final.iloc[selected_index]
            selected_name = selected_stock_data['ì¢…ëª©ëª…']
            code = selected_stock_data['ì¢…ëª©ì½”ë“œ']
            
            if st.session_state.last_code != code:
                st.session_state.messages = []
                st.session_state.last_code = code

            rank = selected_stock_data['í…Œë§ˆìˆœìœ„']
            selected_theme = selected_stock_data['í…Œë§ˆëª…']
            price_info = selected_stock_data['í˜„ì¬ê°€(ë“±ë½ë¥ )']
            
            with st.spinner(f'{selected_name}ì˜ ìƒì„¸ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
                fund_data = get_stock_fundamentals(code)
                m_cap = fund_data['ì‹œê°€ì´ì•¡']
                news_list = get_latest_news(code)
            
            st.subheader(f"2ï¸âƒ£ [{selected_name}] ìƒì„¸ ë¶„ì„ & AI ì±„íŒ…")
            st.info(f"ğŸ’° ì‹œê°€ì´ì•¡: **{m_cap}** | ğŸ† í…Œë§ˆ ë‚´ ìˆœìœ„: **{rank}** | ğŸ·ï¸ í…Œë§ˆ: **{selected_theme}**")
            
            with st.expander("ğŸ’¬ AI íˆ¬ì ì „ëµê°€ì™€ ëŒ€í™”í•˜ê¸° (Click)", expanded=True):
                if not st.session_state.messages:
                    if st.button(f"âš¡ '{selected_name}' ì‹¬ì¸µ ë¶„ì„ ì‹œì‘"):
                        if not GOOG_API_KEY.startswith("AIza"):
                            st.error("ğŸš¨ API í‚¤ í™•ì¸ í•„ìš”")
                        else:
                            news_context = "\n".join([f"- {n['ì œëª©']}" for n in news_list])
                            # [í•µì‹¬] í”„ë¡¬í”„íŠ¸ ìˆ˜ì •: í˜¸ì¬ì™€ ìƒìŠ¹ ëª¨ë©˜í…€ ìš°ì„  ë¶„ì„
                            system_prompt = f"""
                            ë‹¹ì‹ ì€ 'ì €í‰ê°€ ìš°ëŸ‰ì£¼'ì™€ 'ê¸‰ë“± í…Œë§ˆì£¼'ë¥¼ ë°œêµ´í•˜ëŠ” ê³µê²©ì ì¸ íˆ¬ì ì „ëµê°€ì…ë‹ˆë‹¤.
                            ë‹¨ìˆœí•œ ì‚¬ì‹¤ ë‚˜ì—´ë³´ë‹¤ëŠ” **"ì™œ ì´ ì£¼ì‹ì´ ì˜¤ë¥¼ ìˆ˜ë°–ì— ì—†ëŠ”ê°€?"**ì— ì§‘ì¤‘í•˜ì—¬ ë¶„ì„í•˜ì‹­ì‹œì˜¤.
                            
                            [ë¶„ì„ ëŒ€ìƒ]: {selected_name} (í…Œë§ˆ: {selected_theme}, ì‹œì´: {m_cap}, ì£¼ê°€: {price_info})
                            [ìµœì‹  ë‰´ìŠ¤ í—¤ë“œë¼ì¸]: {news_context}
                            
                            ë°˜ë“œì‹œ ë‹¤ìŒ ìˆœì„œì™€ ê´€ì ìœ¼ë¡œ ë¸Œë¦¬í•‘í•˜ì‹­ì‹œì˜¤:
                            
                            ### ğŸš€ 1. í•µì‹¬ í˜¸ì¬ & ìƒìŠ¹ ëª¨ë©˜í…€ (ê°€ì¥ ì¤‘ìš”)
                            - ì œê³µëœ ë‰´ìŠ¤ì™€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì£¼ê°€ ìƒìŠ¹ì„ ê²¬ì¸í•  **ê°€ì¥ ê°•ë ¥í•œ ì¬ë£Œ 3ê°€ì§€**ë¥¼ ì„ ì •í•˜ì—¬ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
                            - ë‹¨ìˆœ ë‰´ìŠ¤ê°€ ì•„ë‹ˆë¼, ì´ê²ƒì´ ì™œ 'ëˆì´ ë˜ëŠ”ì§€' íˆ¬ìì ê´€ì ì—ì„œ í•´ì„í•˜ì‹­ì‹œì˜¤.
                            - (ì˜ˆ: ê¸°ìˆ  ìˆ˜ì¶œ, ì‹¤ì  í„´ì–´ë¼ìš´ë“œ, M&A, ì •ë¶€ ì •ì±… ìˆ˜í˜œ ë“±)
                            
                            ### ğŸ“ˆ 2. í…Œë§ˆ & ì‹œì¥ í†µì°°
                            - ì´ í…Œë§ˆ({selected_theme})ê°€ í˜„ì¬ ì‹œì¥ì—ì„œ ì™œ ì£¼ëª©ë°›ê³  ìˆëŠ”ì§€ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
                            
                            ### ğŸ’¡ 3. ë§¤ë§¤ ì „ëµ & ë¦¬ìŠ¤í¬ ì²´í¬
                            - **ê¸ì •ì  ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ ì „ì œë¡œ ëª©í‘œê°€ë‚˜ ë§¤ìˆ˜ êµ¬ê°„ì„ ë„Œì§€ì‹œ ì œì‹œí•˜ì‹­ì‹œì˜¤.
                            - ë¦¬ìŠ¤í¬ëŠ” ë§ˆì§€ë§‰ì— ì§§ê²Œ ì–¸ê¸‰í•˜ì—¬ ì£¼ì˜ë¥¼ í™˜ê¸°ì‹œí‚¤ëŠ” ì •ë„ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
                            
                            **ì‘ì„± ì›ì¹™:**
                            - ë§íˆ¬ëŠ” í™•ì‹ ì— ì°¬ ì „ë¬¸ê°€ì²˜ëŸ¼ í•˜ì‹­ì‹œì˜¤.
                            - ê°œì¡°ì‹(Bullet points)ìœ¼ë¡œ ê°€ë…ì„±ì„ ë†’ì´ì‹­ì‹œì˜¤.
                            - í˜¸ì¬ì™€ ê¸ì •ì  ì „ë§ì˜ ë¹„ì¤‘ì„ 80%ë¡œ ë‘ì‹­ì‹œì˜¤.
                            """
                            st.session_state.messages.append({"role": "user", "content": system_prompt})
                            with st.chat_message("assistant"):
                                response_text = st.write_stream(get_gemini_response_hojae(st.session_state.messages, selected_real_name, use_grounding, selected_name, selected_theme))
                            st.session_state.messages.append({"role": "assistant", "content": response_text})

                for i, message in enumerate(st.session_state.messages):
                    if i == 0: continue
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])

                if st.session_state.messages:
                    if prompt := st.chat_input(f"{selected_name}ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
                        st.session_state.messages.append({"role": "user", "content": prompt})
                        with st.chat_message("user"):
                            st.markdown(prompt)
                        with st.chat_message("assistant"):
                            response_text = st.write_stream(get_gemini_response_hojae(st.session_state.messages, selected_real_name, use_grounding, selected_name, selected_theme))
                        st.session_state.messages.append({"role": "assistant", "content": response_text})

            col1, col2 = st.columns([1, 1])
            with col1:
                tab1, tab2, tab3 = st.tabs(["ğŸ“… ì¼ë´‰ ì°¨íŠ¸", "ğŸ“† ì£¼ë´‰ ì°¨íŠ¸", "ğŸ“‹ í…Œë§ˆ ì „ì²´ ë³´ê¸°"])
                with tab1: st.image(f"https://ssl.pstatic.net/imgfinance/chart/item/candle/day/{code}.png", use_container_width=True)
                with tab2: st.image(f"https://ssl.pstatic.net/imgfinance/chart/item/candle/week/{code}.png", use_container_width=True)
                with tab3:
                    theme_stocks = df_C[df_C['í…Œë§ˆëª…'] == selected_theme]
                    st.dataframe(theme_stocks[['í…Œë§ˆìˆœìœ„', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€(ë“±ë½ë¥ )']], use_container_width=True, hide_index=True)
            with col2:
                st.markdown(f"##### ğŸ“° ìµœì‹  ë‰´ìŠ¤ (ìµœê·¼ 20ê±´)")
                if news_list:
                    for i, news in enumerate(news_list):
                        st.markdown(f"{i+1}. [{news['ì œëª©']}]({news['ë§í¬']})")
                else: st.info("ìµœì‹  ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else: st.info("ğŸ‘† ìœ„ í‘œì—ì„œ ì¢…ëª©ì„ ì„ íƒí•˜ë©´ AI ë¶„ì„ê³¼ ì°¨íŠ¸ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else: st.warning("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
except Exception as e: st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
