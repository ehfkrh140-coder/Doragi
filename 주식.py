import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import google.generativeai as genai
from duckduckgo_search import DDGS

# ==========================================
# ğŸ”‘ ê¸°ë³¸ ì„¤ì •
# ==========================================
try:
    GOOG_API_KEY = st.secrets["GOOG_API_KEY"]
except:
    GOOG_API_KEY = "ì—¬ê¸°ì—_í‚¤ë¥¼_ë„£ìœ¼ì„¸ìš”"

st.set_page_config(page_title="AI ì£¼ì‹ íˆ¬ì ë¹„ì„œ", layout="wide")
st.title("ğŸ¤– AI ì£¼ì‹ íˆ¬ì ì „ëµê°€ (Real-Time Pro)")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_code" not in st.session_state:
    st.session_state.last_code = None

# --- [ìœ í‹¸ë¦¬í‹°] ---
@st.cache_data
def get_available_gemini_models(api_key):
    try:
        genai.configure(api_key=api_key)
        return [m.name.replace("models/", "") for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    except: return ["gemini-1.5-flash"]

def extract_code(link):
    match = re.search(r'code=([a-zA-Z0-9]+)', link)
    if match: return match.group(1)
    return None

# --- [ê²€ìƒ‰ í•¨ìˆ˜ 1] DuckDuckGo (í•´ì™¸/ì¼ë°˜ ê²€ìƒ‰ìš©) ---
def search_news_robust(keyword):
    search_context = ""
    try:
        results = list(DDGS().news(keywords=keyword, region='kr-kr', max_results=5))
        if not results:
            results = list(DDGS().text(keywords=keyword, region='kr-kr', max_results=5))
        for i, res in enumerate(results):
            title = res.get('title', '-')
            body = res.get('body', res.get('snippet', '-'))
            search_context += f"[DDG-{i+1}] {title}: {body}\n"
    except: pass
    return search_context

# --- [ê²€ìƒ‰ í•¨ìˆ˜ 2] ë„¤ì´ë²„ ì‹œí™© ë‰´ìŠ¤ í¬ë¡¤ë§ (ì‹¤ì‹œê°„ì„± ë³´ì¥ìš©) ---
def get_naver_market_news():
    news_context = ""
    try:
        # ë„¤ì´ë²„ ê¸ˆìœµ 'ì‹œí™©/ì „ë§' ë¦¬ìŠ¤íŠ¸
        url = "https://finance.naver.com/news/news_list.naver?mode=LSS2D&section_id=101&section_id2=258"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë‰´ìŠ¤ ì œëª©ê³¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ
        articles = soup.select("dd.articleSubject > a") + soup.select("dt.articleSubject > a")
        summaries = soup.select("dd.articleSummary")
        
        for i, (art, sum_text) in enumerate(zip(articles[:7], summaries[:7])):
            title = art.text.strip()
            summary = sum_text.text.strip()[:100] # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
            news_context += f"[ë„¤ì´ë²„ë‰´ìŠ¤-{i+1}] {title} // {summary}...\n"
    except Exception as e:
        news_context = f"ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}"
    return news_context

# --- [ë°ì´í„° ìˆ˜ì§‘] Tab 1ìš© ---
@st.cache_data
def get_naver_themes():
    url = "https://finance.naver.com/sise/theme.naver"
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        data = []
        for row in soup.select("#contentarea_left > table.type_1 > tr"):
            cols = row.select("td")
            if len(cols) >= 4:
                data.append({"í…Œë§ˆëª…": cols[0].text.strip(), "ë§í¬": "https://finance.naver.com" + cols[0].find('a')['href']})
        return pd.DataFrame(data).head(20)
    except: return pd.DataFrame()

def get_theme_details(link):
    try:
        res = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        stocks = []
        for row in soup.select("table.type_5 > tbody > tr"):
            cols = row.select("td")
            if len(cols) > 4:
                name = cols[0].text.strip()
                code_match = re.search(r'code=([0-9]+)', cols[0].find('a')['href'])
                code = code_match.group(1) if code_match else ""
                price = cols[2].text.strip()
                rate = cols[4].text.strip().replace('\n', '').strip()
                stocks.append({'name': name, 'code': code, 'price_str': f"{price} ({rate})", 'link': link})
        return stocks
    except: return []

@st.cache_data
def get_market_rankings():
    market_map = {}
    vol_leaders = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    for s in [0, 1]:
        try:
            res = requests.get(f"https://finance.naver.com/sise/sise_rise.naver?sosok={s}", headers=headers)
            soup = BeautifulSoup(res.content.decode('cp949', 'ignore'), 'html.parser')
            for item in soup.select("table.type_2 tr td a.tltle")[:300]: 
                market_map[item.text.strip()] = "KOSPI" if s==0 else "KOSDAQ"
        except: pass
    for s in [0, 1]:
        try:
            res = requests.get(f"https://finance.naver.com/sise/sise_quant_high.naver?sosok={s}", headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            for item in soup.select("table.type_2 tr td a.tltle")[:200]: 
                vol_leaders.append(item.text.strip())
        except: pass
    return market_map, vol_leaders

def get_stock_fundamentals(code):
    try:
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        cap = soup.select_one("#_market_sum").text.strip()
        return {"ì‹œê°€ì´ì•¡": f"{cap}ì–µ"}
    except: return {"ì‹œê°€ì´ì•¡": "-"}

def get_latest_news(code):
    try:
        url = f"https://finance.naver.com/item/news_news.naver?code={code}"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        news_list = []
        for a in soup.select(".title > a")[:20]:
            news_list.append({"ì œëª©": a.text.strip(), "ë§í¬": "https://finance.naver.com"+a['href']})
        return news_list
    except: return []

# --- [AI ì‘ë‹µ í•¨ìˆ˜] ---
def get_gemini_response_robust(messages, model_name, use_search, stock_name, theme):
    genai.configure(api_key=GOOG_API_KEY)
    
    current_query = messages[-1]['content']
    search_res = ""
    if use_search:
        # ê°œë³„ ì¢…ëª© ë¶„ì„ ì‹œì—ë„ ë„¤ì´ë²„ ë‰´ìŠ¤ + DDG ë³‘í–‰
        ddg_res = search_news_robust(f"{stock_name} {theme} í˜¸ì¬ ì „ë§")
        naver_res = get_latest_news(extract_code(theme)) # ê°„ë‹¨ ë‰´ìŠ¤ë§Œ
        search_res = f"\n[ê²€ìƒ‰ ë°ì´í„°]:\n{ddg_res}\n"
    
    modified_msgs = []
    for i, msg in enumerate(messages):
        content = msg['content']
        if i == len(messages)-1: content += search_res
        modified_msgs.append({"role": "user" if msg['role']=="user" else "model", "parts": [content]})
    
    model = genai.GenerativeModel(f"models/{model_name}")
    response = model.generate_content(modified_msgs, stream=True)
    for chunk in response: yield chunk.text

def analyze_market_trend_ai(df, news_data, model_name):
    genai.configure(api_key=GOOG_API_KEY)
    model = genai.GenerativeModel(f"models/{model_name}")
    top_30 = df.head(30).to_string(index=False) # ìƒìœ„ 30ê°œë¡œ ëŠ˜ë¦¼
    
    prompt = f"""
    ë‹¹ì‹ ì€ ì›”ê°€ ì¶œì‹ ì˜ ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. 
    ì œê³µëœ [ì‹¤ì‹œê°„ ì‹œí™© ë‰´ìŠ¤]ì™€ [ì‹œì´ ìƒìœ„ì£¼ íë¦„]ì„ ê²°í•©í•˜ì—¬, í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ì •í™•í•˜ê²Œ ë¸Œë¦¬í•‘í•˜ì„¸ìš”.
    ë‹¨ìˆœíˆ ë“±ë½ë¥ ë§Œ ì½ì§€ ë§ê³ , ë‰´ìŠ¤ì— ë‚˜ì˜¨ ì´ìŠˆ(ê¸ˆë¦¬, ì •ì±…, í•´ì™¸ì¦ì‹œ ë“±)ê°€ ì£¼ê°€ì— ì–´ë–»ê²Œ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ ì—°ê²°í•´ì„œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.

    [ì‹¤ì‹œê°„ ì‹œí™© ë‰´ìŠ¤ ë°ì´í„°]:
    {news_data}

    [ì½”ìŠ¤í”¼ ì‹œì´ ìƒìœ„ 30ìœ„ íë¦„]:
    {top_30}
    
    ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
    ## ğŸ“° ì˜¤ëŠ˜ì˜ ì¦ì‹œ í—¤ë“œë¼ì¸
    (ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì‹œì¥ì˜ í•µì‹¬ ì´ìŠˆ ìš”ì•½)
    ## ğŸŒ ì£¼ë„ ì„¹í„° ë° ìˆ˜ê¸‰ ë¶„ì„
    (ìƒìœ„ì£¼ë“¤ì˜ ì›€ì§ì„ê³¼ ë‰´ìŠ¤ë¥¼ ì—°ê²°í•˜ì—¬ ìƒìŠ¹/í•˜ë½ ì›ì¸ ë¶„ì„)
    ## ğŸ’¡ 34ì„¸ ì§ì¥ì¸ íˆ¬ììë¥¼ ìœ„í•œ ëŒ€ì‘ ì „ëµ
    (ê³µê²©ì ì¸ íˆ¬ì ê´€ì ì—ì„œ í˜„ì¬ ë§¤ìˆ˜í• ë§Œí•œ ì„¹í„°ë‚˜ ê´€ë§ ì—¬ë¶€ ì¡°ì–¸)
    """
    response = model.generate_content(prompt, stream=True)
    for chunk in response: yield chunk.text

# --- [ë°ì´í„° ìˆ˜ì§‘] Tab 2ìš© ---
@st.cache_data
def get_market_cap_top150():
    stocks = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    for page in range(1, 4):
        try:
            res = requests.get(f"https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page={page}", headers=headers)
            soup = BeautifulSoup(res.content.decode('cp949', 'ignore'), 'html.parser')
            for row in soup.select("table.type_2 tbody tr"):
                cols = row.select("td")
                if len(cols) < 10: continue
                stocks.append({
                    "ìˆœìœ„": cols[0].text.strip(), "ì¢…ëª©ëª…": cols[1].text.strip(),
                    "í˜„ì¬ê°€": cols[2].text.strip(), "ë“±ë½ë¥ ": cols[4].text.strip().replace("\n", "").strip(),
                    "ì‹œê°€ì´ì•¡": cols[6].text.strip()
                })
        except: pass
    return pd.DataFrame(stocks)


# ==========================================
# ğŸ–¥ï¸ ë©”ì¸ í™”ë©´ êµ¬ì„±
# ==========================================

with st.sidebar:
    st.header("ğŸ” ì„¤ì •")
    if GOOG_API_KEY.startswith("AIza"):
        models = get_available_gemini_models(GOOG_API_KEY)
        model_name = st.selectbox("ëª¨ë¸ ì„ íƒ", models, index=0)
        selected_real_name = model_name.split(" ")[1] if " " in model_name else model_name
    else:
        st.error("API í‚¤ í•„ìš”")
        selected_real_name = "gemini-1.5-flash"
    use_grounding = st.checkbox("ğŸŒ ì‹¬ì¸µ ê²€ìƒ‰ ì‚¬ìš©", value=True)

tab1, tab2 = st.tabs(["ğŸ¯ ê¸‰ë“±ì£¼ ë°œêµ´ (ê¸°ì¡´)", "ğŸ“Š ì‹œí™© ë¶„ì„ (New)"])

# --- Tab 1 ---
with tab1:
    st.subheader("1ï¸âƒ£ êµì§‘í•© ë¶„ì„ ê²°ê³¼ (í•µì‹¬ ì£¼ë„ì£¼)")
    try:
        with st.spinner('ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
            market_map, vol_leaders = get_market_rankings()
            df_themes = get_naver_themes()
            
            final_candidates = []
            for index, row in df_themes.iterrows():
                stocks_info = get_theme_details(row['ë§í¬'])
                for s in stocks_info:
                    if (s['name'] in market_map) and (s['name'] in vol_leaders):
                        final_candidates.append({
                            "í…Œë§ˆìˆœìœ„": f"{index+1}ìœ„", "ì‹œì¥êµ¬ë¶„": market_map[s['name']],
                            "ì¢…ëª©ëª…": s['name'], "ì¢…ëª©ì½”ë“œ": s['code'],
                            "í˜„ì¬ê°€(ë“±ë½ë¥ )": s['price_str'], "í…Œë§ˆëª…": row['í…Œë§ˆëª…']
                        })
        
        if final_candidates:
            df_final = pd.DataFrame(final_candidates).drop_duplicates(['ì¢…ëª©ëª…'])
            event = st.dataframe(df_final[['í…Œë§ˆìˆœìœ„', 'ì‹œì¥êµ¬ë¶„', 'ì¢…ëª©ëª…', 'í˜„ì¬ê°€(ë“±ë½ë¥ )', 'í…Œë§ˆëª…']], 
                               use_container_width=True, hide_index=True, on_select="rerun", selection_mode="single-row")
            st.divider()
            
            if len(event.selection.rows) > 0:
                sel_idx = event.selection.rows[0]
                sel_data = df_final.iloc[sel_idx]
                s_name = sel_data['ì¢…ëª©ëª…']
                code = sel_data['ì¢…ëª©ì½”ë“œ']
                s_theme = sel_data['í…Œë§ˆëª…']
                
                if st.session_state.last_code != code:
                    st.session_state.messages = []
                    st.session_state.last_code = code

                with st.spinner(f'{s_name} ì •ë³´ ìˆ˜ì§‘ ì¤‘...'):
                    fund = get_stock_fundamentals(code)
                    news_list = get_latest_news(code)
                
                st.subheader(f"2ï¸âƒ£ [{s_name}] ìƒì„¸ ë¶„ì„")
                st.info(f"ğŸ’° ì‹œê°€ì´ì•¡: **{fund['ì‹œê°€ì´ì•¡']}** | ğŸ† í…Œë§ˆ: **{s_theme}**")
                
                with st.expander("ğŸ’¬ AI íˆ¬ì ì „ëµê°€ì™€ ëŒ€í™”í•˜ê¸°", expanded=True):
                    if not st.session_state.messages:
                        if st.button(f"âš¡ '{s_name}' ì‹¬ì¸µ ë¶„ì„ ì‹œì‘"):
                            news_ctx = "\n".join([f"- {n['ì œëª©']}" for n in news_list])
                            sys_prompt = f"""
                            ë‹¹ì‹ ì€ ê³µê²©ì ì¸ íˆ¬ì ì „ëµê°€ì…ë‹ˆë‹¤. {s_name}({s_theme})ì„ í˜¸ì¬ ìœ„ì£¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
                            [ë‰´ìŠ¤]: {news_ctx}
                            ë°˜ë“œì‹œ 'ğŸš€ í•µì‹¬ í˜¸ì¬ 3ê°€ì§€', 'ğŸ“ˆ í…Œë§ˆ ì „ë§', 'ğŸ’¡ ë§¤ë§¤ ì „ëµ' ìˆœì„œë¡œ ë¸Œë¦¬í•‘í•˜ì„¸ìš”.
                            """
                            st.session_state.messages.append({"role": "user", "content": sys_prompt})
                            with st.chat_message("assistant"):
                                res_txt = st.write_stream(get_gemini_response_robust(st.session_state.messages, selected_real_name, use_grounding, s_name, s_theme))
                            st.session_state.messages.append({"role": "assistant", "content": res_txt})

                    for msg in st.session_state.messages:
                        if msg['role'] == 'user' and "ë‹¹ì‹ ì€" in msg['content']: continue
                        with st.chat_message(msg['role']): st.markdown(msg['content'])

                    if prompt := st.chat_input(f"{s_name} ì§ˆë¬¸ ì…ë ¥..."):
                        st.session_state.messages.append({"role": "user", "content": prompt})
                        with st.chat_message("user"): st.markdown(prompt)
                        with st.chat_message("assistant"):
                            res_txt = st.write_stream(get_gemini_response_robust(st.session_state.messages, selected_real_name, use_grounding, s_name, s_theme))
                        st.session_state.messages.append({"role": "assistant", "content": res_txt})

                col1, col2 = st.columns([1, 1])
                with col1:
                    t1, t2 = st.tabs(["ğŸ“… ì¼ë´‰", "ğŸ“† ì£¼ë´‰"])
                    with t1: st.image(f"https://ssl.pstatic.net/imgfinance/chart/item/candle/day/{code}.png", use_container_width=True)
                    with t2: st.image(f"https://ssl.pstatic.net/imgfinance/chart/item/candle/week/{code}.png", use_container_width=True)
                with col2:
                    st.markdown("##### ğŸ“° ìµœì‹  ë‰´ìŠ¤")
                    for i, n in enumerate(news_list):
                        st.markdown(f"{i+1}. [{n['ì œëª©']}]({n['ë§í¬']})")
        else: st.warning("í˜„ì¬ ì¡°ê±´(ê±°ë˜ëŸ‰ 200ìœ„ & ìƒìŠ¹ë¥  300ìœ„)ì„ ë™ì‹œì— ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e: st.error(f"ì˜¤ë¥˜: {e}")

# --- [Tab 2] ì‹œí™© ë¶„ì„ (ê°œì„ ë¨) ---
with tab2:
    st.header("ğŸ“Š ì‹œì¥ ì „ì²´ íë¦„ (ì‹œì´ Top 150)")
    if st.button("ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", key="btn_market"):
        st.session_state.df_market = get_market_cap_top150()
    
    if "df_market" in st.session_state and st.session_state.df_market is not None:
        st.dataframe(st.session_state.df_market, height=400)
        
        st.subheader("ğŸ¤– AI ì‹œí™© ë¸Œë¦¬í•‘")
        if st.button("ğŸ“¢ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„ ì‹œì‘"):
            with st.spinner("1. ë•ë•ê³  ê²€ìƒ‰ ì‹œë„ ì¤‘..."):
                ddg_data = search_news_robust("ì˜¤ëŠ˜ ì£¼ì‹ ì‹œí™© íŠ¹ì§•ì£¼")
            
            with st.spinner("2. ë„¤ì´ë²„ ì‹œí™© ë‰´ìŠ¤ í¬ë¡¤ë§ ì¤‘... (ë°±ì—…)"):
                naver_data = get_naver_market_news()
            
            # ë‘ ë°ì´í„° í•©ì¹˜ê¸°
            combined_news = f"--- [DuckDuckGo ê²€ìƒ‰] ---\n{ddg_data}\n\n--- [ë„¤ì´ë²„ ì‹¤ì‹œê°„ ì‹œí™©] ---\n{naver_data}"
            
            # ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì£¼ê¸° (íˆ¬ëª…ì„±)
            with st.expander("ğŸ” AIê°€ ì°¸ê³ í•œ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ë°ì´í„° ë³´ê¸° (í´ë¦­)", expanded=True):
                st.text(combined_news)
                if len(combined_news) < 50:
                    st.error("ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. AIê°€ ì‹œì´ ë°ì´í„°ë¡œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            with st.spinner("3. AI ë¶„ì„ ìƒì„± ì¤‘..."):
                st.write_stream(analyze_market_trend_ai(st.session_state.df_market, combined_news, selected_real_name))
