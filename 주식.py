import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
import google.generativeai as genai
from duckduckgo_search import DDGS

# ==========================================
# ğŸ”‘ [ê¸°ë³¸ ì„¤ì •] API í‚¤ ë° í˜ì´ì§€
# ==========================================
try:
    GOOG_API_KEY = st.secrets["GOOG_API_KEY"]
except:
    GOOG_API_KEY = "ì—¬ê¸°ì—_í‚¤ë¥¼_ë„£ìœ¼ì„¸ìš”" # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©

st.set_page_config(page_title="AI ì£¼ì‹ íˆ¬ì ë¹„ì„œ", layout="wide")
st.title("ğŸ¤– AI ì£¼ì‹ íˆ¬ì ì „ëµê°€ (Market & Stock)")

# --- [ìœ í‹¸ë¦¬í‹°] ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ---
@st.cache_data
def get_available_models(api_key):
    try:
        genai.configure(api_key=api_key)
        return [m.name.replace("models/", "") for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    except: return ["gemini-1.5-flash"]

# --- [ê²€ìƒ‰ í•¨ìˆ˜] DuckDuckGo + ë„¤ì´ë²„ ë‰´ìŠ¤ ---
def robust_search(keyword):
    search_context = ""
    try:
        # ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œë„
        results = list(DDGS().news(keywords=keyword, region='kr-kr', max_results=5))
        if not results:
            results = list(DDGS().text(keywords=keyword, region='kr-kr', max_results=5))
        
        for i, res in enumerate(results):
            title = res.get('title', '-')
            body = res.get('body', res.get('snippet', '-'))
            search_context += f"[{i+1}] {title}: {body}\n"
    except: 
        search_context = "ì™¸ë¶€ ê²€ìƒ‰ ë°ì´í„° ì—†ìŒ (ë„¤ì´ë²„ ë°ì´í„°ë¡œ ë¶„ì„ ëŒ€ì²´)"
    return search_context

# --- [ë°ì´í„° ìˆ˜ì§‘ 1] ê¸°ì¡´: í…Œë§ˆ, ê±°ë˜ëŸ‰, ê¸‰ë“±ì£¼ ---
@st.cache_data
def get_naver_themes():
    url = "https://finance.naver.com/sise/theme.naver"
    try:
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        data = []
        for row in soup.select("#contentarea_left > table.type_1 > tr"):
            cols = row.select("td")
            if len(cols) >= 4:
                data.append({"í…Œë§ˆëª…": cols[0].text.strip(), "ë§í¬": "https://finance.naver.com" + cols[0].find('a')['href']})
        return pd.DataFrame(data).head(20)
    except: return pd.DataFrame()

def get_theme_stocks(link):
    try:
        res = requests.get(link, headers={'User-Agent': 'Mozilla/5.0'})
        res.encoding = 'cp949'
        soup = BeautifulSoup(res.text, 'html.parser')
        stocks = []
        for row in soup.select("table.type_5 > tbody > tr"):
            cols = row.select("td")
            if len(cols) > 4:
                name = cols[0].text.strip()
                code = re.search(r'code=([0-9]+)', cols[0].find('a')['href']).group(1)
                price = cols[2].text.strip()
                rate = cols[4].text.strip()
                stocks.append({'ì¢…ëª©ëª…': name, 'ì½”ë“œ': code, 'í˜„ì¬ê°€': price, 'ë“±ë½ë¥ ': rate})
        return stocks
    except: return []

@st.cache_data
def get_market_rankings():
    # ê±°ë˜ëŸ‰ ìƒìœ„ & ìƒìŠ¹ë¥  ìƒìœ„ ê°€ì ¸ì˜¤ê¸° (ë²”ìœ„ í™•ëŒ€: 200ìœ„/300ìœ„)
    vol_stocks, rise_stocks = set(), set()
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    # 1. ê±°ë˜ëŸ‰ ìƒìœ„ (ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥)
    for s in [0, 1]:
        try:
            url = f"https://finance.naver.com/sise/sise_quant_high.naver?sosok={s}"
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            for item in soup.select("table.type_2 tr td a.tltle")[:200]: # 200ìœ„ê¹Œì§€
                vol_stocks.add(item.text.strip())
        except: pass
        
    # 2. ìƒìŠ¹ë¥  ìƒìœ„
    for s in [0, 1]:
        try:
            url = f"https://finance.naver.com/sise/sise_rise.naver?sosok={s}"
            res = requests.get(url, headers=headers) # ì¸ì½”ë”© ì´ìŠˆ ìë™ ì²˜ë¦¬
            soup = BeautifulSoup(res.content.decode('cp949', 'ignore'), 'html.parser')
            for item in soup.select("table.type_2 tr td a.tltle")[:300]: # 300ìœ„ê¹Œì§€
                rise_stocks.add(item.text.strip())
        except: pass
            
    return vol_stocks, rise_stocks

# --- [ë°ì´í„° ìˆ˜ì§‘ 2] ì‹ ê·œ: ì‹œê°€ì´ì•¡ ìƒìœ„ 150ìœ„ ---
@st.cache_data
def get_market_cap_top150():
    stocks = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    # ì½”ìŠ¤í”¼(0) ê¸°ì¤€ 1~3í˜ì´ì§€ (í˜ì´ì§€ë‹¹ 50ê°œ)
    for page in range(1, 4):
        url = f"https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page={page}"
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.content.decode('cp949', 'ignore'), 'html.parser')
            rows = soup.select("table.type_2 tbody tr")
            for row in rows:
                cols = row.select("td")
                if len(cols) < 10: continue # ë¹ˆ ì¤„ ì œì™¸
                try:
                    rank = cols[0].text.strip()
                    name = cols[1].text.strip()
                    code = re.search(r'code=([0-9]+)', cols[1].find('a')['href']).group(1)
                    price = cols[2].text.strip()
                    rate = cols[4].text.strip().replace("\n", "").strip()
                    mkt_cap = cols[6].text.strip() # ì‹œê°€ì´ì•¡
                    
                    # ìƒìŠ¹/í•˜ë½ ê¸°í˜¸ ì •ë¦¬
                    if "ìƒìŠ¹" in rate: rate = "+" + rate.replace("ìƒìŠ¹", "").strip()
                    elif "í•˜ë½" in rate: rate = "-" + rate.replace("í•˜ë½", "").strip()
                    
                    stocks.append({
                        "ìˆœìœ„": rank, "ì¢…ëª©ëª…": name, "ì½”ë“œ": code, 
                        "í˜„ì¬ê°€": price, "ë“±ë½ë¥ ": rate, "ì‹œê°€ì´ì•¡(ì–µ)": mkt_cap
                    })
                except: pass
        except: pass
    return pd.DataFrame(stocks)

# --- [AI ë¶„ì„ í•¨ìˆ˜] 1. ê°œë³„ ì¢…ëª© ë¶„ì„ ---
def analyze_stock_detail(name, theme, news_text, search_text, model_name):
    genai.configure(api_key=GOOG_API_KEY)
    model = genai.GenerativeModel(f"models/{model_name}")
    prompt = f"""
    ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ í€ë“œë§¤ë‹ˆì €ì…ë‹ˆë‹¤. {name} ì¢…ëª©(í…Œë§ˆ: {theme})ì„ ë¶„ì„í•˜ì„¸ìš”.
    
    [ë‰´ìŠ¤ ë°ì´í„°]: {news_text}
    [ì›¹ ê²€ìƒ‰ ë°ì´í„°]: {search_text}
    
    ë¶„ì„ í¬ì¸íŠ¸:
    1. ğŸš€ í•µì‹¬ í˜¸ì¬ 3ê°€ì§€ (ìƒìŠ¹ ì¬ë£Œ)
    2. ğŸ“ˆ ì°¨íŠ¸/ìˆ˜ê¸‰ ê´€ì  (ê°„ëµíˆ)
    3. ğŸ’¡ ë§¤ë§¤ ì „ëµ (ëª©í‘œê°€/ì†ì ˆê°€ ì œì•ˆ í¬í•¨)
    """
    response = model.generate_content(prompt, stream=True)
    for chunk in response: yield chunk.text

# --- [AI ë¶„ì„ í•¨ìˆ˜] 2. ì‹œì¥(ì‹œí™©) ë¶„ì„ ---
def analyze_market_trend(df_top, search_text, model_name):
    genai.configure(api_key=GOOG_API_KEY)
    model = genai.GenerativeModel(f"models/{model_name}")
    
    # ìƒìœ„ ì¢…ëª©ë“¤ì˜ íë¦„ì„ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½í•´ì„œ AIì—ê²Œ ì „ë‹¬
    # (í† í° ì ˆì•½ì„ ìœ„í•´ ìƒìœ„ 20ê°œ + ë“±ë½ë¥  í° ìˆœì„œ ì¼ë¶€ë§Œ ë°œì·Œ)
    top_20 = df_top.head(20).to_string(index=False)
    
    # 150ìœ„ ë‚´ì—ì„œ ê°€ì¥ ë§ì´ ì˜¤ë¥¸ 5ê°œ, ë–¨ì–´ì§„ 5ê°œ ì¶”ì¶œ
    try:
        df_sorted = df_top.copy()
        df_sorted['numeric_rate'] = df_sorted['ë“±ë½ë¥ '].str.replace('%','').str.replace('+','').str.replace('-','-').astype(float)
        top_gainers = df_sorted.nlargest(5, 'numeric_rate')[['ì¢…ëª©ëª…', 'ë“±ë½ë¥ ']].to_string(index=False)
        top_losers = df_sorted.nsmallest(5, 'numeric_rate')[['ì¢…ëª©ëª…', 'ë“±ë½ë¥ ']].to_string(index=False)
    except:
        top_gainers = "ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"
        top_losers = "ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"

    prompt = f"""
    ë‹¹ì‹ ì€ ê±°ì‹œê²½ì œì™€ ì£¼ì‹ ì‹œì¥ ì „ì²´ë¥¼ ì½ëŠ” ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
    ì˜¤ëŠ˜ ëŒ€í•œë¯¼êµ­ ì¦ì‹œì˜ 'ì‹œê°€ì´ì•¡ ìƒìœ„ 150ìœ„' íë¦„ê³¼ 'ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼'ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ ì‹œí™©ì„ ë¸Œë¦¬í•‘í•˜ì„¸ìš”.

    [ì‹œì´ ìƒìœ„ 20ìœ„ íë¦„]:
    {top_20}
    
    [150ìœ„ ë‚´ ê¸‰ë“±ì£¼ Top 5]: {top_gainers}
    [150ìœ„ ë‚´ ê¸‰ë½ì£¼ Top 5]: {top_losers}
    
    [ì£¼ìš” ì‹œí™© ë‰´ìŠ¤]:
    {search_text}
    
    ì‘ì„± ì–‘ì‹:
    ## ğŸ“Š ì˜¤ëŠ˜ì˜ ì¦ì‹œ ìš”ì•½ (í•œì¤„í‰)
    ## ğŸŒ ë©”ì¸ ì£¼ë„ í…Œë§ˆ ë° ì„¹í„° ë¶„ì„
    - ì˜¤ëŠ˜ ì‹œì¥ì„ ì´ë„ëŠ” ì—…ì¢…ì€ ë¬´ì—‡ì¸ê°€? (ë°˜ë„ì²´, ë°”ì´ì˜¤, 2ì°¨ì „ì§€ ë“± ì‹œì´ ìƒìœ„ì£¼ ì›€ì§ì„ ê¸°ë°˜)
    - íŠ¹ì§•ì ì¸ ìˆ˜ê¸‰ ì ë¦¼ í˜„ìƒ ë¶„ì„
    ## ğŸ“° ì£¼ìš” ì´ìŠˆ ì²´í¬
    - ê²€ìƒ‰ëœ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œì¥ì— ì˜í–¥ì„ ì¤€ ê±°ì‹œ ê²½ì œ ì´ìŠˆ(ê¸ˆë¦¬, í™˜ìœ¨, í•´ì™¸ ì¦ì‹œ ë“±) ì–¸ê¸‰
    ## ğŸ’¡ íˆ¬ìì ëŒ€ì‘ ì „ëµ
    - í˜„ì¬ ì¥ì„¸ì—ì„œì˜ í¬íŠ¸í´ë¦¬ì˜¤ ì „ëµ (ê³µê²©ì  ë§¤ìˆ˜ vs ê´€ë§ ë“±)
    """
    
    response = model.generate_content(prompt, stream=True)
    for chunk in response: yield chunk.text

# ==========================================
# ğŸ–¥ï¸ ë©”ì¸ í™”ë©´ êµ¬ì„±
# ==========================================

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì • íŒ¨ë„")
    if GOOG_API_KEY.startswith("AIza"):
        models = get_available_models(GOOG_API_KEY)
        selected_model = st.selectbox("AI ëª¨ë¸", models, index=0)
    else:
        st.error("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
        selected_model = "gemini-1.5-flash"
    
    st.info("ë°ì´í„° ë²”ìœ„: ê±°ë˜ëŸ‰ ìƒìœ„ 200ìœ„ / ìƒìŠ¹ë¥  ìƒìœ„ 300ìœ„ / ì‹œì´ ìƒìœ„ 150ìœ„")

# íƒ­ êµ¬ì„±
tab1, tab2 = st.tabs(["ğŸ¯ ê¸‰ë“±ì£¼/í…Œë§ˆ ë°œêµ´", "ğŸ“Š ì‹œì´ ìƒìœ„ & ì‹œí™© ë¶„ì„"])

# --- [Tab 1] ê¸°ì¡´ ê¸°ëŠ¥: êµì§‘í•© ì¢…ëª© ë°œêµ´ ---
with tab1:
    st.header("ğŸ¯ êµì§‘í•© ê¸‰ë“±ì£¼ ë°œêµ´")
    if st.button("ë°ì´í„° ë¶„ì„ ì‹œì‘ (Tab 1)", key="btn1"):
        with st.spinner("ì‹œì¥ ë°ì´í„°ë¥¼ ìƒ…ìƒ…ì´ ë’¤ì§€ëŠ” ì¤‘..."):
            vol_set, rise_set = get_market_rankings()
            df_themes = get_naver_themes()
            
            final_list = []
            
            # í…Œë§ˆë³„ ì¢…ëª© ìˆœíšŒ
            progress = st.progress(0)
            for idx, row in df_themes.iterrows():
                t_name = row['í…Œë§ˆëª…']
                stocks = get_theme_stocks(row['ë§í¬'])
                
                for s in stocks:
                    # êµì§‘í•© ì¡°ê±´ ì²´í¬
                    if (s['ì¢…ëª©ëª…'] in vol_set) and (s['ì¢…ëª©ëª…'] in rise_set):
                        final_list.append({
                            "í…Œë§ˆ": t_name, "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'], 
                            "í˜„ì¬ê°€": s['í˜„ì¬ê°€'], "ë“±ë½ë¥ ": s['ë“±ë½ë¥ '], "ì½”ë“œ": s['ì½”ë“œ']
                        })
                progress.progress((idx + 1) / len(df_themes))
            
            if final_list:
                df_result = pd.DataFrame(final_list).drop_duplicates('ì¢…ëª©ëª…')
                st.success(f"ì¡°ê±´ ë§Œì¡± ì¢…ëª© {len(df_result)}ê°œ ë°œê²¬!")
                st.dataframe(df_result)
                
                # ê°œë³„ ë¶„ì„ ê¸°ëŠ¥
                selected_stock = st.selectbox("ì‹¬ì¸µ ë¶„ì„í•  ì¢…ëª© ì„ íƒ", df_result['ì¢…ëª©ëª…'].unique())
                if st.button(f"âš¡ {selected_stock} AI ë¶„ì„"):
                    row = df_result[df_result['ì¢…ëª©ëª…'] == selected_stock].iloc[0]
                    with st.spinner(f"{selected_stock} ë‰´ìŠ¤ ë° ì •ë³´ ìˆ˜ì§‘ ì¤‘..."):
                        search_q = f"{selected_stock} {row['í…Œë§ˆ']} ì£¼ê°€ ì „ë§"
                        search_data = robust_search(search_q)
                        st.write_stream(analyze_stock_detail(selected_stock, row['í…Œë§ˆ'], "ë„¤ì´ë²„ë‰´ìŠ¤ ë°ì´í„°", search_data, selected_model))
            else:
                st.warning("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (í•„í„°ë§ ë²”ìœ„ë¥¼ 300ìœ„ê¹Œì§€ ë„“í˜”ìœ¼ë‚˜ ë°œê²¬ë˜ì§€ ì•ŠìŒ)")

# --- [Tab 2] ì‹ ê·œ ê¸°ëŠ¥: ì‹œì´ ìƒìœ„ & ì‹œí™© ë¶„ì„ ---
with tab2:
    st.header("ğŸ“Š ì‹œì¥ ì „ì²´ íë¦„ (ì‹œì´ Top 150)")
    
    if "df_market" not in st.session_state:
        st.session_state.df_market = None

    col_btn, col_info = st.columns([1, 3])
    with col_btn:
        if st.button("ì‹œí™© ë°ì´í„° ê°€ì ¸ì˜¤ê¸°", key="btn2"):
            with st.spinner("ì½”ìŠ¤í”¼ ì‹œê°€ì´ì•¡ ìƒìœ„ 150ê°œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                st.session_state.df_market = get_market_cap_top150()
    
    if st.session_state.df_market is not None:
        df = st.session_state.df_market
        
        # 1. ë°ì´í„° í‘œì‹œ
        st.dataframe(df, height=300)
        
        # 2. AI ì‹œí™© ë¶„ì„ ë²„íŠ¼
        st.subheader("ğŸ¤– AI ìˆ˜ì„ ì• ë„ë¦¬ìŠ¤íŠ¸ì˜ ì‹œì¥ ë¸Œë¦¬í•‘")
        if st.button("ğŸ“¢ í˜„ì¬ ì‹œì¥ ìƒí™© ë¶„ì„í•˜ê¸°"):
            with st.spinner("ì£¼ìš” ë‰´ìŠ¤ ê²€ìƒ‰ ë° ìˆ˜ê¸‰ ë¶„ì„ ì¤‘..."):
                # ê²€ìƒ‰ì–´ ì„¤ì •
                search_keywords = "ì˜¤ëŠ˜ ì£¼ì‹ ì‹œí™© ì£¼ë„ í…Œë§ˆ íŠ¹ì§•ì£¼"
                search_data = robust_search(search_keywords)
                
                # ë¶„ì„ ì‹¤í–‰
                st.write_stream(analyze_market_trend(df, search_data, selected_model))
                
                # ê²€ìƒ‰ëœ ë‰´ìŠ¤ ì¶œì²˜ í‘œì‹œ
                with st.expander("ì°¸ê³ í•œ ë‰´ìŠ¤ ë°ì´í„° ë³´ê¸°"):
                    st.text(search_data)
